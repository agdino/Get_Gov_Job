# -*- coding: utf-8 -*-
import re
import os
import time
import json
import requests
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service
from bs4 import BeautifulSoup

# ===== Telegram ç’°å¢ƒè®Šæ•¸ =====
BOT_TOKEN = os.getenv("TG_BOT_TOKEN")
CHAT_ID = os.getenv("TG_CHAT_ID")

def send_telegram_message(text: str):
    """ç™¼é€æ–‡å­—è¨Šæ¯åˆ° Telegram"""
    if not BOT_TOKEN or not CHAT_ID:
        print("âŒ ç¼ºå°‘ TG_BOT_TOKEN æˆ– TG_CHAT_ID")
        return
    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    payload = {"chat_id": CHAT_ID, "text": text, "parse_mode": "HTML"}
    try:
        requests.post(url, data=payload)
        print("âœ… å·²ç™¼é€ Telegram é€šçŸ¥ã€‚")
    except Exception as e:
        print("âŒ ç™¼é€å¤±æ•—ï¼š", e)


# ===== æŠ“å–è·ç¼ºè³‡æ–™ =====
def fetch_job_html(keyword="çµ±è¨ˆ"):
    """ä½¿ç”¨ Selenium å–å¾—è·ç¼º HTML (å„ªåŒ– GitHub Actions ç©©å®šæ€§)"""
    url = "https://web3.dgpa.gov.tw/want03front/AP/WANTF00001.ASPX"

    options = webdriver.ChromeOptions()
    
    # 1. (é—œéµ) å°‡é é¢è¼‰å…¥ç­–ç•¥è¨­ç‚º 'eager'
    # è®“ driver.get() åœ¨ DOM æº–å‚™å°±ç·’å¾Œå°±è¿”å›ï¼Œä¸ç­‰å¾…æ‰€æœ‰è³‡æºè¼‰å…¥
    # æ¥è‘—ç”± WebDriverWait ä¾†ç­‰å¾…æˆ‘å€‘éœ€è¦çš„ç‰¹å®šå…ƒç´ 
    options.page_load_strategy = 'eager'

    # 2. (é—œéµ) ç§»é™¤ç¡¬ç·¨ç¢¼è·¯å¾‘
    # ä¾è³´ GitHub Actions YML ä¸­ (ä¾‹å¦‚ browser-actions/setup-chrome@v1)
    # è‡ªå‹•å®‰è£ä¸¦åŠ å…¥åˆ° PATH çš„ chromedriver å’Œ chromium-browser
    # options.binary_location = "/usr/bin/chromium-browser" # ç§»é™¤
    
    # --- ä¿ç•™æ‰€æœ‰ GitHub Actions éœ€è¦çš„åƒæ•¸ ---
    options.add_argument("--headless=new")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    options.add_argument("--disable-software-rasterizer")
    options.add_argument("--disable-features=VizDisplayCompositor")
    options.add_argument("--remote-debugging-port=9222")
    options.add_argument("--window-size=1920,1080")
    options.add_argument("--ignore-certificate-errors")
    options.add_argument("--disable-extensions")
    options.add_argument("--disable-infobars")
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_argument(
        "--user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 "
        "(KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    )

    # 3. (é—œéµ) è®“ Selenium è‡ªå‹•å°‹æ‰¾é©…å‹•ç¨‹å¼
    # service = Service("/usr/bin/chromedriver") # ç§»é™¤
    # driver = webdriver.Chrome(service=service, options=options) # èˆŠç‰ˆ
    driver = webdriver.Chrome(options=options) # æ–°ç‰ˆ (Selenium 4+)

    # 4. (å„ªåŒ–) å»¶é•·ç­‰å¾…æ™‚é–“
    # å°‡ WebDriverWait å»¶é•·åˆ° 60 ç§’ï¼Œèˆ‡ page_load_timeout ä¸€è‡´
    # è®“å…ƒç´ æœ‰æ›´å……è£•çš„æ™‚é–“åœ¨è³‡æºå—é™çš„ç’°å¢ƒä¸­è¢«è¼‰å…¥
    wait = WebDriverWait(driver, 60) 
    driver.set_page_load_timeout(60)

    try:
        print("é é¢è¼‰å…¥ä¸­ (Eager ç­–ç•¥)...")
        driver.get(url)
        # time.sleep(2) # ç§»é™¤ï¼šä½¿ç”¨ eager ç­–ç•¥å¾Œï¼Œæ‡‰å®Œå…¨ä¾è³´ WebDriverWait

        # ç­‰å¾…è¼¸å…¥æ¡†å‡ºç¾
        input_box = wait.until(
            EC.presence_of_element_located(
                (By.CSS_SELECTOR, 'div#ctl00_ContentPlaceHolder1_trPerson4 input')
            )
        )
        print("è¼¸å…¥æ¡†å·²è¼‰å…¥ã€‚")
        
        input_box.clear()
        input_box.send_keys(keyword)
        time.sleep(1) # é€™è£¡çš„çŸ­æš«åœé “æœ‰åŠ©æ–¼æ¨¡æ“¬è¼¸å…¥
        input_box.send_keys(Keys.ARROW_DOWN)
        input_box.send_keys(Keys.ENTER)
        print(f"å·²é¸å–ã€{keyword}ã€")

        # ç­‰å¾…æŸ¥è©¢æŒ‰éˆ•å¯è¢«é»æ“Š
        search_button = wait.until(
            EC.element_to_be_clickable(
                (By.ID, "ctl00_ContentPlaceHolder1_btnQUERY")
            )
        )
        search_button.click()
        print("æŸ¥è©¢ä¸­...")
        
        # 5. (å„ªåŒ–) é»æ“Šå¾Œç­‰å¾…è¡¨æ ¼å‡ºç¾
        # ä¸ä½¿ç”¨ time.sleep(3)ï¼Œè€Œæ˜¯æ˜ç¢ºç­‰å¾…è¡¨æ ¼æ¨™è¨˜å‡ºç¾
        wait.until(
            EC.presence_of_element_located((By.XPATH, "//table[contains(., 'è·ç¨±') or contains(., 'æ©Ÿé—œåç¨±')]"))
        )
        print("æŸ¥è©¢çµæœè¡¨æ ¼å·²è¼‰å…¥ã€‚")
        
        # åŸ·è¡Œ JS æŠ“å–è¡¨æ ¼
        table_html = driver.execute_script("""
            let tables = document.querySelectorAll('table');
            for (let t of tables) {
                if (t.innerText.includes('è·ç¨±') || 
                    t.innerText.includes('æ©Ÿé—œåç¨±') || 
                    t.innerText.includes('çµ±è¨ˆ')) {
                    return t.outerHTML;
                }
            }
            return '';
        """)

        if not table_html:
            raise Exception("æ²’æœ‰æ‰¾åˆ°è·ç¼ºè¡¨æ ¼")

        print("âœ… å·²å–å¾—è¡¨æ ¼ HTMLã€‚")
        return table_html

    except Exception as e:
        print("âŒ æŠ“å–éŒ¯èª¤ï¼š", e)
        # (å¯é¸) å¢åŠ é™¤éŒ¯è³‡è¨Š
        # driver.save_screenshot("debug_screenshot.png")
        # print(driver.page_source)
        raise
    finally:
        driver.quit()


# ===== è§£æèˆ‡åˆ‡å‰² =====
TITLE_KEYWORDS = [
    "æ›¸è¨˜å®˜", "ç§‘å“¡", "åŠ©ç†å“¡", "å°ˆå“¡", "æŠ€å£«", "åˆ†æå¸«", "è¾¦äº‹å“¡", "æŠ€ä½", "ä¸»ä»»", "å¹¹äº‹"
]

pattern = re.compile(
    r"""
    ^\s*
    (?P<åºè™Ÿ>\d+)
    (?P<å‰åŠ>.+?)
    \[?(?P<è·ç³»>[\u4e00-\u9fa5A-Za-z0-9]+)\]?[,]?
    (?P<å·¥ä½œåœ°é»>\d{1,3}-[\u4e00-\u9fa5A-Za-z0-9]+)
    (?P<è·å‹™åˆ—ç­‰>(å§”ä»»|è–¦ä»»|ç°¡ä»»).*?è·ç­‰(?:æˆ–.*?è·ç­‰)*)
    æœ‰æ•ˆæœŸé–“[:ï¼š]?\s*(?P<æœ‰æ•ˆæœŸé–“>\d{3}/\d{2}/\d{2}\s*~\s*\d{3}/\d{2}/\d{2})
    (?P<å‚™è¨»>.*)$
    """, re.X
)

def split_title_and_org(text: str):
    for kw in TITLE_KEYWORDS:
        if kw in text:
            pos = text.find(kw) + len(kw)
            return text[:pos], text[pos:].strip()
    return text[:3], text[3:].strip()

def parse_jobs(html: str):
    """è§£æ HTML è¡¨æ ¼æˆçµæ§‹åŒ–è³‡æ–™"""
    soup = BeautifulSoup(html, "html.parser")
    rows = soup.find_all("tr")
    print(f"ğŸ” å…±æ‰¾åˆ° {len(rows)} åˆ— (å«è¡¨é ­)")

    if rows and ("è·ç¨±" in rows[0].get_text() or "æ©Ÿé—œåç¨±" in rows[0].get_text()):
        rows = rows[1:]

    data = []
    for row in rows:
        line = "".join(td.get_text(strip=True) for td in row.find_all("td"))
        if not line or "å…±" in line:
            continue

        m = pattern.search(line)
        if m:
            title, org = split_title_and_org(m.group("å‰åŠ"))
            data.append({
                "è·ç¨±": title,
                "æ©Ÿé—œåç¨±": org,
                "è·ç³»": m.group("è·ç³»"),
                "è·å‹™åˆ—ç­‰": m.group("è·å‹™åˆ—ç­‰"),
                "å·¥ä½œåœ°é»": m.group("å·¥ä½œåœ°é»"),
                "æœ‰æ•ˆæœŸé–“": m.group("æœ‰æ•ˆæœŸé–“"),
            })
    print(f"âœ… æˆåŠŸè§£æ {len(data)} ç­†ã€‚")
    return data


# ===== ä¸»æµç¨‹ =====
def main():
    try:
        html = fetch_job_html("çµ±è¨ˆ")
        jobs = parse_jobs(html)

        if not jobs:
            send_telegram_message("âš ï¸ ä»Šå¤©æ²’æœ‰æŠ“åˆ°ä»»ä½•è·ç¼ºã€‚")
            return

        preview = jobs[:5]
        msg_lines = ["ğŸ“Š <b>ä»Šæ—¥çµ±è¨ˆè·ç¼ºæ›´æ–°ï¼š</b>"]
        for i, j in enumerate(preview, 1):
            msg_lines.append(
                f"\n<b>{i}. {j['è·ç¨±']}</b>ï¼ˆ{j['è·ç³»']}ï¼‰\n"
                f"ğŸ“ {j['æ©Ÿé—œåç¨±']}ï½œ{j['å·¥ä½œåœ°é»']}\n"
                f"ğŸ’¼ {j['è·å‹™åˆ—ç­‰']}\n"
                f"â° {j['æœ‰æ•ˆæœŸé–“']}"
            )

        send_telegram_message("\n".join(msg_lines))

    except Exception as e:
        err_msg = f"âŒ ä»»å‹™åŸ·è¡Œå¤±æ•—ï¼š{str(e)}"
        print(err_msg)
        send_telegram_message(err_msg)


if __name__ == "__main__":
    main()

